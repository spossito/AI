{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Version: 0.4.34\n",
      "Pytorch Version: 2.5.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# Importamos\n",
    "\n",
    "import jax\n",
    "import torch\n",
    "import warnings\n",
    "import jax.numpy as jaxnp\n",
    "\n",
    "from torch.func import jacfwd\n",
    "\n",
    "# Logging \n",
    "\n",
    "warnings.filterwarnings('ignore', category = UserWarning)\n",
    "\n",
    "# Version \n",
    "\n",
    "print(f'JAX Version: {jax.__version__}')\n",
    "print(f'Pytorch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Jacobiana** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #1**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = X^2$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$X^2 = XX$$\n",
    "$$vec(ABC) = (C^T \\otimes A) \\cdot vec(B)$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(X^2) = X dX + dX  X$$\n",
    "$$d(X^2) = X  dX  I + I  dX  X$$\n",
    "$$d(X^2) = vec(XdXI) + vec(IdXX)$$\n",
    "$$d(X^2) = (I \\otimes X) \\cdot vec(dX) + (X^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(X^2) = (I \\otimes X + X^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = I \\otimes X + X^T \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[2., 2., 3., 0.],\n",
      "        [3., 5., 0., 3.],\n",
      "        [2., 0., 5., 2.],\n",
      "        [0., 2., 3., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = torch.matmul(X, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestra matriz de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jacfwd(Fn, argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jacobian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "[[2. 2. 3. 0.]\n",
      " [3. 5. 0. 3.]\n",
      " [2. 0. 5. 2.]\n",
      " [0. 2. 3. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestra matriz de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jax.jacfwd(Fn, argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jaxnp.moveaxis(jacobian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[2., 2., 3., 0.],\n",
      "        [3., 5., 0., 3.],\n",
      "        [2., 0., 5., 2.],\n",
      "        [0., 2., 3., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "I = torch.eye(2) \n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "jacobian = torch.kron(I, X) + torch.kron(X.T.contiguous(), I)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #2**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = XCX$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$vec(ABC) = (C^T \\otimes A) \\cdot vec(B)$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(XCX) = XCdX + XdCX + dXCX$$\n",
    "$$d(XCX) = XCdXI + IdXCX$$\n",
    "$$d(XCX) = vec(XCdXI) + vec(IdXCX)$$\n",
    "$$d(XCX) = (I \\otimes XC) \\cdot vec(dX) + ((CX)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(XCX) = (I \\otimes XC + (CX)^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = I \\otimes XC + (CX)^T \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[53., 23., 26.,  0.],\n",
      "        [44., 90.,  0., 26.],\n",
      "        [52.,  0., 56., 23.],\n",
      "        [ 0., 52., 44., 93.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, C):   \n",
    "    \n",
    "    output = torch.matmul(X, C)\n",
    "    output = torch.matmul(output, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jacfwd(Fn, argnums = 0)(X, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jacobian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "[[53. 23. 26.  0.]\n",
      " [44. 90.  0. 26.]\n",
      " [52.  0. 56. 23.]\n",
      " [ 0. 52. 44. 93.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, C):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, C)\n",
    "    output = jaxnp.matmul(output, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = jaxnp.array([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jax.jacfwd(Fn, argnums = 0)(X, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jaxnp.moveaxis(jacobian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[53., 23., 26.,  0.],\n",
      "        [44., 90.,  0., 26.],\n",
      "        [52.,  0., 56., 23.],\n",
      "        [ 0., 52., 44., 93.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "I = torch.eye(2) \n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "jacobian = torch.kron(I, torch.matmul(X, C)) + torch.kron(torch.matmul(C, X).T.contiguous(), I)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #3**\n",
    "\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = AXB$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$vec(ABC) = (C^T \\otimes A) \\cdot vec(B)$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(AXB) = AXdB + AdXB + dAXB$$\n",
    "$$d(AXB) = AdXB$$\n",
    "$$d(AXB) = vec(AdXB)$$\n",
    "$$d(AXB) = (B^T \\otimes A) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = B^T \\otimes A$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[64., 72., 40., 45.],\n",
      "        [40., 56., 25., 35.],\n",
      "        [72., 40., 45., 25.],\n",
      "        [72., 81., 56., 63.],\n",
      "        [45., 63., 35., 49.],\n",
      "        [81., 45., 63., 35.],\n",
      "        [48., 54.,  8.,  9.],\n",
      "        [30., 42.,  5.,  7.],\n",
      "        [54., 30.,  9.,  5.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(A, X, B):   \n",
    "    \n",
    "    output = torch.matmul(A, X)\n",
    "    output = torch.matmul(output, B)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "A = torch.tensor([[8.0, 9.0], [5.0, 7.0], [9.0, 5.0]]) \n",
    "B = torch.tensor([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0]])\n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el segundo argumento 1 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jacfwd(Fn, argnums = 1)(A, X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jacobian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "[[64. 72. 40. 45.]\n",
      " [40. 56. 25. 35.]\n",
      " [72. 40. 45. 25.]\n",
      " [72. 81. 56. 63.]\n",
      " [45. 63. 35. 49.]\n",
      " [81. 45. 63. 35.]\n",
      " [48. 54.  8.  9.]\n",
      " [30. 42.  5.  7.]\n",
      " [54. 30.  9.  5.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(A, X, B):   \n",
    "    \n",
    "    output = jaxnp.matmul(A, X)\n",
    "    output = jaxnp.matmul(output, B)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "A = jaxnp.array([[8.0, 9.0], [5.0, 7.0], [9.0, 5.0]]) \n",
    "B = jaxnp.array([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0]])\n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el segundo argumento 1 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jax.jacfwd(Fn, argnums = 1)(A, X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jaxnp.moveaxis(jacobian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[64., 72., 40., 45.],\n",
      "        [40., 56., 25., 35.],\n",
      "        [72., 40., 45., 25.],\n",
      "        [72., 81., 56., 63.],\n",
      "        [45., 63., 35., 49.],\n",
      "        [81., 45., 63., 35.],\n",
      "        [48., 54.,  8.,  9.],\n",
      "        [30., 42.,  5.,  7.],\n",
      "        [54., 30.,  9.,  5.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "A = torch.tensor([[8.0, 9.0], [5.0, 7.0], [9.0, 5.0]]) \n",
    "B = torch.tensor([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0]])\n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "jacobian = torch.kron(B.T.contiguous(), A) \n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #4**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = XAX^TB$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$vec(ABC) = (C^T \\otimes A) \\cdot vec(B)$$\n",
    "$$vec(dX^T) = K_{m, n} \\cdot vec(dX)$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(XAX^TB) = XAX^TdB + XAdX^TB + XdAX^TB + dXAX^TB$$\n",
    "$$d(XAX^TB) = XAdX^TB + dXAX^TB$$\n",
    "$$d(XAX^TB) = vec(XAdX^TB) + vec(dXAX^TB)$$\n",
    "$$d(XAX^TB) = (B^T \\otimes XA) \\cdot vec(dX^T) + ((AX^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(XAX^TB) = (B^T \\otimes XA) \\cdot K_{m, n} \\cdot vec(dX) + ((AX^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(XAX^TB) = ((B^T \\otimes XA) \\cdot K_{m, n} +  ((AX^TB)^T \\otimes I))\\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = (B^T \\otimes XA) \\cdot K_{m, n} +  (AX^TB)^T \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[1471.,   90.,  126., 1111.,  115.,  161.],\n",
      "        [ 352., 1547.,  308.,  440., 1202.,  385.],\n",
      "        [ 776.,  485., 2006.,  928.,  580., 1739.],\n",
      "        [1518.,  126.,  108., 1159.,  161.,  138.],\n",
      "        [ 396., 1664.,  264.,  495., 1337.,  330.],\n",
      "        [ 873.,  679., 1938., 1044.,  812., 1648.],\n",
      "        [ 792.,   18.,   72.,  615.,   23.,   92.],\n",
      "        [ 264.,  728.,  176.,  330.,  532.,  220.],\n",
      "        [ 582.,   97., 1072.,  696.,  116.,  941.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(A, X, B):   \n",
    "    \n",
    "    output = torch.matmul(X, A)\n",
    "    output = torch.matmul(output, X.T)\n",
    "    output = torch.matmul(output, B)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0], [9.0, 5.0]]) \n",
    "A = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "B = torch.tensor([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0], [7.0, 6.0, 4.0]])\n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el segundo argumento 1 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jacfwd(Fn, argnums = 1)(A, X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jacobian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "[[1471.   90.  126. 1111.  115.  161.]\n",
      " [ 352. 1547.  308.  440. 1202.  385.]\n",
      " [ 776.  485. 2006.  928.  580. 1739.]\n",
      " [1518.  126.  108. 1159.  161.  138.]\n",
      " [ 396. 1664.  264.  495. 1337.  330.]\n",
      " [ 873.  679. 1938. 1044.  812. 1648.]\n",
      " [ 792.   18.   72.  615.   23.   92.]\n",
      " [ 264.  728.  176.  330.  532.  220.]\n",
      " [ 582.   97. 1072.  696.  116.  941.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(A, X, B):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, A)\n",
    "    output = jaxnp.matmul(output, X.T)\n",
    "    output = jaxnp.matmul(output, B)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0], [9.0, 5.0]]) \n",
    "A = jaxnp.array([[8.0, 9.0], [5.0, 7.0]]) \n",
    "B = jaxnp.array([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0], [7.0, 6.0, 4.0]])\n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el segundo argumento 1 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jax.jacfwd(Fn, argnums = 1)(A, X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jaxnp.moveaxis(jacobian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[1471.,   90.,  126., 1111.,  115.,  161.],\n",
      "        [ 352., 1547.,  308.,  440., 1202.,  385.],\n",
      "        [ 776.,  485., 2006.,  928.,  580., 1739.],\n",
      "        [1518.,  126.,  108., 1159.,  161.,  138.],\n",
      "        [ 396., 1664.,  264.,  495., 1337.,  330.],\n",
      "        [ 873.,  679., 1938., 1044.,  812., 1648.],\n",
      "        [ 792.,   18.,   72.,  615.,   23.,   92.],\n",
      "        [ 264.,  728.,  176.,  330.,  532.,  220.],\n",
      "        [ 582.,   97., 1072.,  696.,  116.,  941.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0], [9.0, 5.0]]) \n",
    "A = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "B = torch.tensor([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0], [7.0, 6.0, 4.0]])\n",
    "\n",
    "I = torch.eye(3)\n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "term_1 = torch.kron(B.T.contiguous(), torch.matmul(X, A)) \n",
    "term_2 = torch.kron(torch.matmul(torch.matmul(A, X.T.contiguous()), B).T.contiguous(), I)\n",
    "\n",
    "# Conmutamos ya que existe vec(dX.T)\n",
    "\n",
    "n = B.shape[0]\n",
    "m = X.shape[1] \n",
    "\n",
    "commuted_indices = torch.arange(n * m).reshape(n, m).T.reshape(-1)\n",
    "\n",
    "term1_commuted = term_1[:, commuted_indices]\n",
    "\n",
    "# Calculamos el Jacobiano\n",
    "\n",
    "jacobian = term1_commuted.reshape(term_1.shape) + term_2\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #5**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = XCX^T$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$vec(ABC) = (C^T \\otimes A) \\cdot vec(B)$$\n",
    "$$vec(dX^T) = K_{m, n} \\cdot vec(dX)$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(XCX^T) = XCdX^T + XdCX^T + dXCX^T$$\n",
    "$$d(XCX^T) = XCdX^TI + IdXCX^T$$\n",
    "$$d(XCX^T) = vec(XCdX^TI) + vec(IdXCX^T)$$\n",
    "$$d(XCX^T) = (I \\otimes XC) \\cdot vec(dX^T) + ((CX^T)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(XCX^T) = (I \\otimes XC) \\cdot K_{m, n} \\cdot vec(dX) + ((CX^T)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(XCX^T) = ((I \\otimes XC) \\cdot K_{m, n} + (CX^T)^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = (I \\otimes XC) \\cdot K_{m, n} + (CX^T)^T \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[ 44.,   0.,  42.,   0.],\n",
      "        [ 44.,  26.,  55.,  19.],\n",
      "        [ 60.,  18.,  43.,  23.],\n",
      "        [  0., 104.,   0.,  98.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, C):   \n",
    "    \n",
    "    output = torch.matmul(X, C)\n",
    "    output = torch.matmul(output, X.T)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jacfwd(Fn, argnums = 0)(X, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jacobian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "[[ 44.   0.  42.   0.]\n",
      " [ 44.  26.  55.  19.]\n",
      " [ 60.  18.  43.  23.]\n",
      " [  0. 104.   0.  98.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, C):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, C)\n",
    "    output = jaxnp.matmul(output, X.T)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = jaxnp.array([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jax.jacfwd(Fn, argnums = 0)(X, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jaxnp.moveaxis(jacobian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[ 44.,   0.,  42.,   0.],\n",
      "        [ 44.,  26.,  55.,  19.],\n",
      "        [ 60.,  18.,  43.,  23.],\n",
      "        [  0., 104.,   0.,  98.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "I = torch.eye(2)\n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "term_1 = torch.kron(I, torch.matmul(X, C)) \n",
    "term_2 = torch.kron(torch.matmul(C, X.T.contiguous()).T.contiguous(), I)\n",
    "\n",
    "# Conmutamos ya que existe vec(dX.T)\n",
    "\n",
    "n = C.shape[0]\n",
    "m = X.shape[1] \n",
    "\n",
    "commuted_indices = torch.arange(n * m).reshape(n, m).T.reshape(-1)\n",
    "\n",
    "term1_commuted = term_1[:, commuted_indices]\n",
    "\n",
    "# Calculamos el Jacobiano\n",
    "\n",
    "jacobian = term1_commuted.reshape(term_1.shape) + term_2\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #6**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = X^{-1}$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$vec(ABC) = (C^T \\otimes A) \\cdot vec(B)$$\n",
    "\n",
    "$$I = XX^{-1}$$\n",
    "$$dI = XdX^{-1} + dXX^{-1}$$\n",
    "$$0 = XdX^{-1} + dXX^{-1}$$\n",
    "$$XdX^{-1} = - (dXX^{-1})$$\n",
    "$$X^{-1}XdX^{-1} = - (X^{-1}dXX^{-1})$$\n",
    "$$dX^{-1} = - (X^{-1}dXX^{-1})$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(X^{-1}) = dX^{-1}$$\n",
    "$$d(X^{-1}) = - (X^{-1}dXX^{-1})$$\n",
    "$$d(X^{-1}) = - vec(X^{-1}dXX^{-1})$$\n",
    "$$d(X^{-1}) = ((X^{-1})^T \\otimes X^{-1}) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = (X^{-1})^T \\otimes X^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[-4.0000,  2.0000,  3.0000, -1.5000],\n",
      "        [ 3.0000, -1.0000, -2.2500,  0.7500],\n",
      "        [ 2.0000, -1.0000, -1.0000,  0.5000],\n",
      "        [-1.5000,  0.5000,  0.7500, -0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = torch.linalg.inv(X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestra matriz de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jacfwd(Fn, argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jacobian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "[[-4.000001    2.0000005   3.0000007  -1.5000004 ]\n",
      " [ 3.0000007  -1.0000002  -2.2500005   0.7500002 ]\n",
      " [ 2.0000005  -1.0000002  -1.0000002   0.5000001 ]\n",
      " [-1.5000004   0.5000001   0.7500002  -0.25000006]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = jaxnp.linalg.inv(X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestra matriz de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Calculamos la Matriz Jacobiana (Indicamos con respecto a que argumento derivamos en nuestro caso el primer argumento 0 --> X) (forward-mode)\n",
    "\n",
    "jacobian = jax.jacfwd(Fn, argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (jacobian.shape[0] * jacobian.shape[1], jacobian.shape[2] * jacobian.shape[3])\n",
    "\n",
    "jacobian = jaxnp.moveaxis(jacobian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Jacobiano Respecto a X: \n",
      "tensor([[-4.0000,  2.0000,  3.0000, -1.5000],\n",
      "        [ 3.0000, -1.0000, -2.2500,  0.7500],\n",
      "        [ 2.0000, -1.0000, -1.0000,  0.5000],\n",
      "        [-1.5000,  0.5000,  0.7500, -0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestra matriz de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "jacobian = - torch.kron((torch.linalg.inv(X).contiguous()).T.contiguous(), torch.linalg.inv(X).contiguous()) \n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'El Jacobiano Respecto a X: \\n{jacobian}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatrixCalculus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
