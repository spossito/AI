{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Version: 0.4.34\n",
      "Pytorch Version: 2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "# Importamos\n",
    "\n",
    "import jax\n",
    "import torch\n",
    "import warnings\n",
    "import jax.numpy as jaxnp\n",
    "\n",
    "from torch.func import jacrev\n",
    "\n",
    "# Logging \n",
    "\n",
    "warnings.filterwarnings('ignore', category = UserWarning)\n",
    "\n",
    "# Version \n",
    "\n",
    "print(f'JAX Version: {jax.__version__}')\n",
    "print(f'Pytorch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hessiana desde Gradientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #1**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = \\text{Tr}(X^2B)$$\n",
    "\n",
    "**Primera Derivada:**\n",
    "\n",
    "$$F(X) = \\text{Tr}(XXB)$$\n",
    "$$F(X) = \\text{Tr}(BXX)$$\n",
    "$$df(X) = \\text{Tr}(d(BXX))$$\n",
    "$$df(X) = \\text{Tr}(BXdX + BdXX + dBXX)$$\n",
    "$$df(X) = \\text{Tr}(BXdX + BdXX)$$\n",
    "$$df(X) = \\text{Tr}(BXdX) +  \\text{Tr}(BdXX)$$\n",
    "$$df(X) = \\text{Tr}(BXdX) +  \\text{Tr}(XBdX)$$\n",
    "\n",
    "**Gradiente:** \n",
    "\n",
    "$$(\\nabla X)^T = BX + XB$$\n",
    "$$\\nabla X = (BX + XB)^T$$\n",
    "\n",
    "**Segunda Derivada:**\n",
    "\n",
    "$$df(X) = (BX + XB)^T$$\n",
    "$$df(X) = X^TB^T + B^TX^T$$\n",
    "$$df^2(X) = dX^TB^T + X^TdB^T + dB^TX^T + B^TdX^T$$\n",
    "$$df^2(X) = dX^TB^T + B^TdX^T$$\n",
    "$$df^2(X) = IdX^TB^T + B^TdX^TI$$\n",
    "$$df^2(X) = vec(IdX^TB^T) + vec(B^TdX^TI)$$\n",
    "$$df^2(X) = (B \\otimes I) \\cdot vec(dX^T) + (I \\otimes B^T) \\cdot vec(dX^T)$$\n",
    "$$df^2(X) = (B \\otimes I) \\cdot K_{m, n} \\cdot vec(dX) + (I \\otimes B^T) \\cdot K_{m, n} \\cdot vec(dX)$$\n",
    "$$df^2(X) = ((B \\otimes I) \\cdot K_{m, n} + (I \\otimes B^T) \\cdot K_{m, n}) \\cdot vec(dX)$$\n",
    "\n",
    "**Hessiana:**\n",
    "\n",
    "$$H = (B \\otimes I) \\cdot K_{m, n} + (I \\otimes B^T) \\cdot K_{m, n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[10.,  2.,  5.,  1.,  0.,  0.,  5.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., 12.,  2.,  5.,  1.,  0.,  0.],\n",
      "        [ 5.,  0.,  0.,  2.,  0.,  0.,  6.,  2.,  5.],\n",
      "        [ 1., 12.,  2.,  0.,  1.,  0.,  0.,  5.,  0.],\n",
      "        [ 0.,  2.,  0.,  1., 14.,  2.,  0.,  1.,  0.],\n",
      "        [ 0.,  5.,  0.,  0.,  2.,  0.,  1.,  8.,  2.],\n",
      "        [ 5.,  1.,  6.,  0.,  0.,  1.,  0.,  0.,  5.],\n",
      "        [ 0.,  0.,  2.,  5.,  1.,  8.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  5.,  0.,  0.,  2.,  5.,  1.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, B):   \n",
    "    \n",
    "    output = torch.matmul(X, X) \n",
    "    output = torch.matmul(output, B)\n",
    "    output = torch.trace(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0, 7.0], [3.0, 4.0, 9.0], [5.0, 4.0, 1.0]], requires_grad = True)\n",
    "B = torch.tensor([[5.0, 2.0, 5.0], [1.0, 7.0, 2.0], [5.0, 1.0, 1.0]], requires_grad = False)\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jacrev(jacrev(Fn, argnums = 0), argnums = 0)(X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1], hessian.shape[2] * hessian.shape[3])\n",
    "\n",
    "hessian = hessian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "[[10.  2.  5.  1.  0.  0.  5.  0.  0.]\n",
      " [ 2.  0.  0. 12.  2.  5.  1.  0.  0.]\n",
      " [ 5.  0.  0.  2.  0.  0.  6.  2.  5.]\n",
      " [ 1. 12.  2.  0.  1.  0.  0.  5.  0.]\n",
      " [ 0.  2.  0.  1. 14.  2.  0.  1.  0.]\n",
      " [ 0.  5.  0.  0.  2.  0.  1.  8.  2.]\n",
      " [ 5.  1.  6.  0.  0.  1.  0.  0.  5.]\n",
      " [ 0.  0.  2.  5.  1.  8.  0.  0.  1.]\n",
      " [ 0.  0.  5.  0.  0.  2.  5.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, B):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, X) \n",
    "    output = jaxnp.matmul(output, B)\n",
    "    output = jaxnp.trace(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0, 7.0], [3.0, 4.0, 9.0], [5.0, 4.0, 1.0]])\n",
    "B = jaxnp.array([[5.0, 2.0, 5.0], [1.0, 7.0, 2.0], [5.0, 1.0, 1.0]])\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jax.jacrev(jax.jacrev(Fn, argnums = 0), argnums = 0)(X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1], hessian.shape[2] * hessian.shape[3])\n",
    "\n",
    "hessian = jaxnp.moveaxis(hessian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[10.,  2.,  5.,  1.,  0.,  0.,  5.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., 12.,  2.,  5.,  1.,  0.,  0.],\n",
      "        [ 5.,  0.,  0.,  2.,  0.,  0.,  6.,  2.,  5.],\n",
      "        [ 1., 12.,  2.,  0.,  1.,  0.,  0.,  5.,  0.],\n",
      "        [ 0.,  2.,  0.,  1., 14.,  2.,  0.,  1.,  0.],\n",
      "        [ 0.,  5.,  0.,  0.,  2.,  0.,  1.,  8.,  2.],\n",
      "        [ 5.,  1.,  6.,  0.,  0.,  1.,  0.,  0.,  5.],\n",
      "        [ 0.,  0.,  2.,  5.,  1.,  8.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  5.,  0.,  0.,  2.,  5.,  1.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos Nuestras Matrices\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0, 7.0], [3.0, 4.0, 9.0], [5.0, 4.0, 1.0]])\n",
    "B = torch.tensor([[5.0, 2.0, 5.0], [1.0, 7.0, 2.0], [5.0, 1.0, 1.0]])\n",
    "\n",
    "I = torch.eye(3)\n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "term_1 = torch.kron(B, I) \n",
    "term_2 = torch.kron(I, B.T.contiguous()) \n",
    "\n",
    "# Conmutamos ya que existe vec(dX.T)\n",
    "\n",
    "n = B.shape[0]\n",
    "m = X.shape[1] \n",
    "\n",
    "commuted_indices = torch.arange(n * m).reshape(n, m).T.reshape(-1)\n",
    "\n",
    "term1_commuted = term_1[:, commuted_indices]\n",
    "term2_commuted = term_2[:, commuted_indices]\n",
    "\n",
    "# Hessiana\n",
    "\n",
    "hessian = term1_commuted.reshape(term_1.shape) + term2_commuted.reshape(term_2.shape)\n",
    "\n",
    "# Visualizamos \n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #2**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = \\text{Tr}(AXBX^TC)$$\n",
    "\n",
    "**Primera Derivada:**\n",
    "\n",
    "$$df(X) = \\text{Tr}(d(AXBX^TC))$$\n",
    "$$df(X) = \\text{Tr}(AXBX^TdC + AXBdX^TC + AXdBX^TC + AdXBX^TC + dAXBX^TC)$$\n",
    "$$df(X) = \\text{Tr}(AXBdX^TC + AdXBX^TC)$$\n",
    "$$df(X) = \\text{Tr}(AXBdX^TC) +  \\text{Tr}(AdXBX^TC)$$\n",
    "$$df(X) = \\text{Tr}(dX^TCAXB) +  \\text{Tr}(BX^TCAdX)$$\n",
    "$$df(X) = \\text{Tr}(dX^TCAXB) +  \\text{Tr}(BX^TCAdX)$$\n",
    "$$df(X) = \\text{Tr}(B^TX^TA^TC^TdX) +  \\text{Tr}(BX^TCAdX)$$\n",
    "\n",
    "**Gradiente:** \n",
    "\n",
    "$$(\\nabla X)^T = B^TX^TA^TC^T + BX^TCA$$\n",
    "$$\\nabla X = CAXB + A^TC^TXB^T$$\n",
    "\n",
    "**Segunda Derivada:**\n",
    "\n",
    "$$df(X) = CAXB + A^TC^TXB^T$$\n",
    "$$df^2(X) = dCAXB + CdAXB + CAdXB + CAXdB + dA^TC^TXB^T + A^TdC^TXB^T + A^TC^TdXB^T + A^TC^TXdB^T$$\n",
    "$$df^2(X) = CAdXB + A^TC^TdXB^T$$\n",
    "$$df^2(X) =  vec(CAdXB) + vec(A^TC^TdXB^T)$$\n",
    "$$df^2(X) =  (B^T \\otimes CA) \\cdot vec(dX) + (B \\otimes A^TC^T) \\cdot vec(dX)$$\n",
    "$$df^2(X) =  (B^T \\otimes CA + B \\otimes A^TC^T) \\cdot vec(dX)$$\n",
    "\n",
    "**Hessiana:**\n",
    "\n",
    "$$H = B^T \\otimes CA + B \\otimes A^TC^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[290., 250., 390.,  87.,  62., 123., 290., 250., 390., 406., 298., 570.],\n",
      "        [250., 180., 325.,  88.,  54., 116., 250., 180., 325., 402., 252., 529.],\n",
      "        [390., 325., 500., 111.,  79., 150., 390., 325., 500., 522., 381., 700.],\n",
      "        [ 87.,  88., 111., 406., 350., 546.,  87.,  62., 123., 290., 146., 438.],\n",
      "        [ 62.,  54.,  79., 350., 252., 455.,  88.,  54., 116., 354., 180., 473.],\n",
      "        [123., 116., 150., 546., 455., 700., 111.,  79., 150., 342., 177., 500.],\n",
      "        [290., 250., 390.,  87.,  88., 111.,  58.,  50.,  78., 290., 146., 438.],\n",
      "        [250., 180., 325.,  62.,  54.,  79.,  50.,  36.,  65., 354., 180., 473.],\n",
      "        [390., 325., 500., 123., 116., 150.,  78.,  65., 100., 342., 177., 500.],\n",
      "        [406., 402., 522., 290., 354., 342., 290., 354., 342., 522., 450., 702.],\n",
      "        [298., 252., 381., 146., 180., 177., 146., 180., 177., 450., 324., 585.],\n",
      "        [570., 529., 700., 438., 473., 500., 438., 473., 500., 702., 585., 900.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, A, B, C):   \n",
    "    \n",
    "    output = torch.matmul(A, X) \n",
    "    output = torch.matmul(output, B)\n",
    "    output = torch.matmul(output, X.T)\n",
    "    output = torch.matmul(output, C)\n",
    "    output = torch.trace(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0, 7.0, 5.0], [3.0, 4.0, 9.0, 1.0], [5.0, 4.0, 1.0, 3.0]], requires_grad = True)\n",
    "A = torch.tensor([[5.0, 2.0, 5.0], [1.0, 7.0, 2.0]], requires_grad = False)\n",
    "B = torch.tensor([[5.0, 2.0, 5.0, 9.0], [1.0, 7.0, 2.0, 9.0], [5.0, 1.0, 1.0, 9.0], [5.0, 1.0, 1.0, 9.0]], requires_grad = False)\n",
    "C = torch.tensor([[5.0, 4.0], [2.0, 2.0], [8.0, 5.0]], requires_grad = False)\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jacrev(jacrev(Fn, argnums = 0), argnums = 0)(X, A, B, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1], hessian.shape[2] * hessian.shape[3])\n",
    "\n",
    "hessian = hessian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "[[290. 250. 390.  87.  62. 123. 290. 250. 390. 406. 298. 570.]\n",
      " [250. 180. 325.  88.  54. 116. 250. 180. 325. 402. 252. 529.]\n",
      " [390. 325. 500. 111.  79. 150. 390. 325. 500. 522. 381. 700.]\n",
      " [ 87.  88. 111. 406. 350. 546.  87.  62. 123. 290. 146. 438.]\n",
      " [ 62.  54.  79. 350. 252. 455.  88.  54. 116. 354. 180. 473.]\n",
      " [123. 116. 150. 546. 455. 700. 111.  79. 150. 342. 177. 500.]\n",
      " [290. 250. 390.  87.  88. 111.  58.  50.  78. 290. 146. 438.]\n",
      " [250. 180. 325.  62.  54.  79.  50.  36.  65. 354. 180. 473.]\n",
      " [390. 325. 500. 123. 116. 150.  78.  65. 100. 342. 177. 500.]\n",
      " [406. 402. 522. 290. 354. 342. 290. 354. 342. 522. 450. 702.]\n",
      " [298. 252. 381. 146. 180. 177. 146. 180. 177. 450. 324. 585.]\n",
      " [570. 529. 700. 438. 473. 500. 438. 473. 500. 702. 585. 900.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, A, B, C):   \n",
    "    \n",
    "    output = jaxnp.matmul(A, X) \n",
    "    output = jaxnp.matmul(output, B)\n",
    "    output = jaxnp.matmul(output, X.T)\n",
    "    output = jaxnp.matmul(output, C)\n",
    "    output = jaxnp.trace(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0, 7.0, 5.0], [3.0, 4.0, 9.0, 1.0], [5.0, 4.0, 1.0, 3.0]])\n",
    "A = jaxnp.array([[5.0, 2.0, 5.0], [1.0, 7.0, 2.0]])\n",
    "B = jaxnp.array([[5.0, 2.0, 5.0, 9.0], [1.0, 7.0, 2.0, 9.0], [5.0, 1.0, 1.0, 9.0], [5.0, 1.0, 1.0, 9.0]])\n",
    "C = jaxnp.array([[5.0, 4.0], [2.0, 2.0], [8.0, 5.0]])\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jax.jacrev(jax.jacrev(Fn, argnums = 0), argnums = 0)(X, A, B, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1], hessian.shape[2] * hessian.shape[3])\n",
    "\n",
    "hessian = jaxnp.moveaxis(hessian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[290., 250., 390.,  87.,  62., 123., 290., 250., 390., 406., 298., 570.],\n",
      "        [250., 180., 325.,  88.,  54., 116., 250., 180., 325., 402., 252., 529.],\n",
      "        [390., 325., 500., 111.,  79., 150., 390., 325., 500., 522., 381., 700.],\n",
      "        [ 87.,  88., 111., 406., 350., 546.,  87.,  62., 123., 290., 146., 438.],\n",
      "        [ 62.,  54.,  79., 350., 252., 455.,  88.,  54., 116., 354., 180., 473.],\n",
      "        [123., 116., 150., 546., 455., 700., 111.,  79., 150., 342., 177., 500.],\n",
      "        [290., 250., 390.,  87.,  88., 111.,  58.,  50.,  78., 290., 146., 438.],\n",
      "        [250., 180., 325.,  62.,  54.,  79.,  50.,  36.,  65., 354., 180., 473.],\n",
      "        [390., 325., 500., 123., 116., 150.,  78.,  65., 100., 342., 177., 500.],\n",
      "        [406., 402., 522., 290., 354., 342., 290., 354., 342., 522., 450., 702.],\n",
      "        [298., 252., 381., 146., 180., 177., 146., 180., 177., 450., 324., 585.],\n",
      "        [570., 529., 700., 438., 473., 500., 438., 473., 500., 702., 585., 900.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos Nuestras Matrices\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0, 7.0, 5.0], [3.0, 4.0, 9.0, 1.0], [5.0, 4.0, 1.0, 3.0]], requires_grad = True)\n",
    "A = torch.tensor([[5.0, 2.0, 5.0], [1.0, 7.0, 2.0]], requires_grad = False)\n",
    "B = torch.tensor([[5.0, 2.0, 5.0, 9.0], [1.0, 7.0, 2.0, 9.0], [5.0, 1.0, 1.0, 9.0], [5.0, 1.0, 1.0, 9.0]], requires_grad = False)\n",
    "C = torch.tensor([[5.0, 4.0], [2.0, 2.0], [8.0, 5.0]], requires_grad = False)\n",
    "\n",
    "I = torch.eye(3)\n",
    "\n",
    "# Hessiana\n",
    "\n",
    "hessian = torch.kron(B.T.contiguous(), torch.matmul(C, A)) + torch.kron(B, torch.matmul(A.T.contiguous(), C.T.contiguous()))\n",
    "\n",
    "# Visualizamos \n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #3**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = \\, \\|X\\|_F^2$$\n",
    "\n",
    "**Primera Derivada:**\n",
    "\n",
    "$$df(X) = \\text{Tr}(d(X X^T))$$\n",
    "$$df(X) = \\text{Tr}(XdX^T + dXX^T)$$\n",
    "$$df(X) = \\text{Tr}(dXX^T + dXX^T)$$\n",
    "$$df(X) = \\text{Tr}(dXX^T) +  \\text{Tr}(dXX^T)$$\n",
    "$$df(X) = \\text{Tr}(X^TdX) +  \\text{Tr}(X^TdX)$$\n",
    "\n",
    "**Gradiente:** \n",
    "\n",
    "$$(\\nabla X)^T = X^T + X^T = 2X^T$$\n",
    "$$\\nabla X = 2X$$\n",
    "\n",
    "**Segunda Derivada:**\n",
    "\n",
    "$$df(X) = 2X$$\n",
    "$$df^2(X) = 2dX$$\n",
    "$$df^2(X) = 2IdXI$$\n",
    "$$df^2(X) = 2 \\cdot vec(IdXI)$$\n",
    "$$df^2(X) = 2 \\cdot (I \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Hessiana:**\n",
    "\n",
    "$$H = 2 \\cdot (I \\otimes I)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = torch.norm(X)**2 \n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos Nuestra Matriz de Ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0, 7.0, 5.0], [3.0, 4.0, 9.0, 1.0], [5.0, 4.0, 1.0, 3.0], [9.0, 5.0, 7.0, 2.0]], requires_grad = True)\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jacrev(jacrev(Fn, argnums = 0), argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1], hessian.shape[2] * hessian.shape[3])\n",
    "\n",
    "hessian = hessian.T.permute(2, 3, 0, 1).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "[[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = jaxnp.linalg.norm(X)**2 \n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos Nuestra Matriz de Ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0, 7.0, 5.0], [3.0, 4.0, 9.0, 1.0], [5.0, 4.0, 1.0, 3.0], [9.0, 5.0, 7.0, 2.0]])\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jax.jacrev(jax.jacrev(Fn, argnums = 0), argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1], hessian.shape[2] * hessian.shape[3])\n",
    "\n",
    "hessian = jaxnp.moveaxis(hessian.T, (0, 1, 2, 3), (2, 3, 0, 1)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos Nuestras Matrices\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0, 7.0, 5.0], [3.0, 4.0, 9.0, 1.0], [5.0, 4.0, 1.0, 3.0], [9.0, 5.0, 7.0, 2.0]], requires_grad = True)\n",
    "\n",
    "I = torch.eye(4)\n",
    "\n",
    "# Hessiana\n",
    "\n",
    "hessian = 2 * torch.kron(I, I)\n",
    "\n",
    "# Visualizamos \n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hessiana desde Jacobianas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #1**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = X^2$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$\\frac{dX}{X} = E_{i, j}$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$d(X) = X dX + dX  X$$\n",
    "$$d(X) = X  dX  I + I  dX  X$$\n",
    "$$d(X) = vec(XdXI) + vec(IdXX)$$\n",
    "$$d(X) = (I \\otimes X) \\cdot vec(dX) + (X^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$d(X) = (I \\otimes X + X^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = I \\otimes X + X^T \\otimes I$$\n",
    "\n",
    "**Segunda Derivada:** \n",
    "\n",
    "$$df(X) = X dX + dX  X$$\n",
    "$$df(X) = XdX_{1} + dX_{1}X$$\n",
    "$$df^2(X) = dX_{2}dX_{1} + XdX_{1}^2 + dX_{1}dX_{2} + dX_{1}^2X$$\n",
    "$$df^2(X) = dX_{2}dX_{1} + dX_{1}dX_{2}$$\n",
    "$$df^2(X) = E_{i, j}dX_{1} + dX_{1}E_{i, j}$$\n",
    "$$df^2(X) = E_{i, j}dX_{1}I + IdX_{1}E_{i, j}$$\n",
    "$$df^2(X) = vec(E_{i, j}dX_{1}I) + vec(IdX_{1}E_{i, j})$$\n",
    "$$df^2(X) = (I \\otimes E_{i, j}) \\cdot vec(dX) + (E_{i, j}^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes E_{i, j} + E_{i, j}^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Segunda Derivada (Desde Producto Kronecker):** \n",
    "\n",
    "$$df(X) = (I \\otimes X + X^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (dI \\otimes X + I \\otimes d(X) + d(X^T) \\otimes I + X^T \\otimes dI) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes d(X) + d(X^T) \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes dX + dX^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes E_{i, j} + E_{i, j}^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Hessiana:**\n",
    "\n",
    "$$H = I \\otimes E_{i, j} + E_{i, j}^T \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[2., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = torch.matmul(X, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos Nuestra Matriz de Ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jacrev(jacrev(Fn, argnums = 0), argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1] * hessian.shape[2], hessian.shape[3] * hessian.shape[4] * hessian.shape[5])\n",
    "\n",
    "hessian = hessian.T.permute(3, 4, 5, 0, 1, 2).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "[[2. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos Nuestra Matriz de Ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jax.jacrev(jax.jacrev(Fn, argnums = 0), argnums = 0)(X)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1] * hessian.shape[2], hessian.shape[3] * hessian.shape[4] * hessian.shape[5])\n",
    "\n",
    "hessian = jaxnp.moveaxis(hessian.T, (0, 1, 2, 3, 4, 5), (3, 4, 5, 0, 1, 2)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[2., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos Nuestras Matrices\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "\n",
    "I = torch.eye(2) \n",
    "\n",
    "# Añadimos Dimensiones Adicionales\n",
    "\n",
    "I = torch.unsqueeze(I, dim = 0)\n",
    "\n",
    "# Tensor Canonico \n",
    "\n",
    "E1 = torch.tensor([[1, 0], [0, 0]], dtype = torch.float32)\n",
    "E2 = torch.tensor([[0, 0], [1, 0]], dtype = torch.float32)\n",
    "E3 = torch.tensor([[0, 1], [0, 0]], dtype = torch.float32)\n",
    "E4 = torch.tensor([[0, 0], [0, 1]], dtype = torch.float32)\n",
    "\n",
    "E_ij = torch.stack([E1, E2, E3, E4])\n",
    "\n",
    "# Hessiana\n",
    "\n",
    "hessian = torch.kron(I, E_ij) + torch.kron(E_ij.permute(0, 2, 1).contiguous(), I)\n",
    "hessian = hessian.permute(0, 2, 1).reshape(8, 8).T\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #2**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = XCX$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$\\frac{dX}{X} = E_{i, j}$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$df(X) = XCdX + XdCX + dXCX$$\n",
    "$$df(X) = XCdX + dXCX$$\n",
    "$$df(X) = XCdXI + IdXCX$$\n",
    "$$df(X) = vec(XCdXI) + vec(IdXCX)$$\n",
    "$$df(X) = (I \\otimes XC) \\cdot vec(dX) + ((CX)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df(X) = (I \\otimes XC + (CX)^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = I \\otimes XC + (CX)^T \\otimes I$$\n",
    "\n",
    "**Segunda Derivada:** \n",
    "\n",
    "$$df(X) = XCdX + dXCX$$\n",
    "$$df(X) = XCdX_{1} + dX_{1}CX$$\n",
    "$$df^2(X) = dX_{2}CdX_{1} + XdCdX_{1} + XCdX_{1}^2 + dX_{1}^2CX + dX_{1}dCX + dX_{1}CdX_{2}$$\n",
    "$$df^2(X) = dX_{2}CdX_{1} + dX_{1}CdX_{2}$$\n",
    "$$df^2(X) = E_{i, j}CdX_{1} + dX_{1}CE_{i, j}$$\n",
    "$$df^2(X) = E_{i, j}CdX_{1}I + IdX_{1}CE_{i, j}$$\n",
    "$$df^2(X) = vec(E_{i, j}CdX_{1}I) + vec(IdX_{1}CE_{i, j})$$\n",
    "$$df^2(X) = (I \\otimes E_{i, j}C) \\cdot vec(dX) + (E_{i, j}^TC^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes E_{i, j}C + E_{i, j}^TC^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Segunda Derivada (Desde Producto Kronecker):** \n",
    "\n",
    "$$df(X) = (I \\otimes XC + (CX)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df(X) = (I \\otimes XC + X^TC^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (dI \\otimes XC + I \\otimes d(XC) + d(X^TC^T) \\otimes I + X^TC^T \\otimes dI) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes d(XC) + d(X^TC^T) \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes dXC + dX^TC^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (I \\otimes E_{i, j}C + E_{i, j}^TC^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Hessiana:**\n",
    "\n",
    "$$H = I \\otimes E_{i, j}C + E_{i, j}^TC^T \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[16.,  5.,  9.,  7.,  5.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  8.,  0.,  0.,  0.,  5.,  0.],\n",
      "        [ 0.,  8.,  0.,  0.,  8., 10.,  9.,  7.],\n",
      "        [ 0.,  0.,  0.,  8.,  0.,  0.,  0.,  5.],\n",
      "        [ 9.,  0.,  0.,  0.,  7.,  0.,  0.,  0.],\n",
      "        [ 8.,  5., 18.,  7.,  0.,  0.,  7.,  0.],\n",
      "        [ 0.,  9.,  0.,  0.,  0.,  7.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  9.,  8.,  5.,  9., 14.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, C):   \n",
    "    \n",
    "    output = torch.matmul(X, C)\n",
    "    output = torch.matmul(output, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jacrev(jacrev(Fn, argnums = 0), argnums = 0)(X, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1] * hessian.shape[2], hessian.shape[3] * hessian.shape[4] * hessian.shape[5])\n",
    "\n",
    "hessian = hessian.T.permute(3, 4, 5, 0, 1, 2).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "[[16.  5.  9.  7.  5.  0.  0.  0.]\n",
      " [ 0.  0.  8.  0.  0.  0.  5.  0.]\n",
      " [ 0.  8.  0.  0.  8. 10.  9.  7.]\n",
      " [ 0.  0.  0.  8.  0.  0.  0.  5.]\n",
      " [ 9.  0.  0.  0.  7.  0.  0.  0.]\n",
      " [ 8.  5. 18.  7.  0.  0.  7.  0.]\n",
      " [ 0.  9.  0.  0.  0.  7.  0.  0.]\n",
      " [ 0.  0.  0.  9.  8.  5.  9. 14.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(X, C):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, C)\n",
    "    output = jaxnp.matmul(output, X)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = jaxnp.array([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el primer argumento 0 --> X) (backward-mode)\n",
    "\n",
    "hessian = jax.jacrev(jax.jacrev(Fn, argnums = 0), argnums = 0)(X, C)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1] * hessian.shape[2], hessian.shape[3] * hessian.shape[4] * hessian.shape[5])\n",
    "\n",
    "hessian = jaxnp.moveaxis(hessian.T, (0, 1, 2, 3, 4, 5), (3, 4, 5, 0, 1, 2)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[16.,  5.,  9.,  7.,  5.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  8.,  0.,  0.,  0.,  5.,  0.],\n",
      "        [ 0.,  8.,  0.,  0.,  8., 10.,  9.,  7.],\n",
      "        [ 0.,  0.,  0.,  8.,  0.,  0.,  0.,  5.],\n",
      "        [ 9.,  0.,  0.,  0.,  7.,  0.,  0.,  0.],\n",
      "        [ 8.,  5., 18.,  7.,  0.,  0.,  7.,  0.],\n",
      "        [ 0.,  9.,  0.,  0.,  0.,  7.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  9.,  8.,  5.,  9., 14.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos Nuestras Matrices\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) \n",
    "C = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "\n",
    "I = torch.eye(2) \n",
    "\n",
    "# Añadimos Dimensiones Adicionales\n",
    "\n",
    "C = torch.unsqueeze(C, dim = 0)\n",
    "I = torch.unsqueeze(I, dim = 0)\n",
    "\n",
    "# Tensor Canonico\n",
    "\n",
    "E1 = torch.tensor([[1, 0], [0, 0]], dtype = torch.float32)\n",
    "E2 = torch.tensor([[0, 0], [1, 0]], dtype = torch.float32)\n",
    "E3 = torch.tensor([[0, 1], [0, 0]], dtype = torch.float32)\n",
    "E4 = torch.tensor([[0, 0], [0, 1]], dtype = torch.float32)\n",
    "\n",
    "E_ij = torch.stack([E1, E2, E3, E4])\n",
    "\n",
    "# Hessiana\n",
    "\n",
    "hessian = torch.kron(I, E_ij @ C) + torch.kron(E_ij.permute(0, 2, 1) @ C.permute(0, 2, 1), I)\n",
    "hessian = hessian.permute(0, 2, 1).reshape(8, 8).T\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio #3**\n",
    "\n",
    "**Funcion:**\n",
    "\n",
    "$$F(X) = XAX^TB$$\n",
    "\n",
    "**Artificios:** \n",
    "\n",
    "$$\\frac{dX}{X} = E_{i, j}$$\n",
    "\n",
    "**Derivada:**\n",
    "\n",
    "$$df(X) = XAX^TdB + XAdX^TB + XdAX^TB + dXAX^TB$$\n",
    "$$df(X) = XAdX^TB + dXAX^TB$$\n",
    "$$df(X) = vec(XAdX^TB) + vec(dXAX^TB)$$\n",
    "$$df(X) = (B^T \\otimes XA) \\cdot vec(dX^T) + ((AX^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df(X) = (B^T \\otimes XA) \\cdot K_{m, n} \\cdot vec(dX) + ((AX^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df(X) = ((B^T \\otimes XA) \\cdot K_{m, n} +  ((AX^TB)^T \\otimes I))\\cdot vec(dX)$$\n",
    "\n",
    "**Jacobiana:** \n",
    "\n",
    "$$J = (B^T \\otimes XA) \\cdot K_{m, n} +  (AX^TB)^T \\otimes I$$\n",
    "\n",
    "**Segunda Derivada:** \n",
    "\n",
    "$$df(X) = XAdX^TB + dXAX^TB$$\n",
    "$$df(X) = XAdX_{1}^TB + dX_{1}AX^TB$$\n",
    "$$df^2(X) = dX_{2}AdX_{1}^TB + XdAdX_{1}^TB + XA(dX_{1}^2)^TB + XAdX_{1}^TdB + dX_{1}^2AX^TB + dX_{1}dAX^TB + dX_{1}AdX_{2}^TB + dX_{1}AX^TdB$$\n",
    "$$df^2(X) = dX_{2}AdX_{1}^TB + dX_{1}AdX_{2}^TB$$\n",
    "$$df^2(X) = E_{i, j}AdX_{1}^TB + dX_{1}AE_{i, j}^TB$$\n",
    "$$df^2(X) = vec(E_{i, j}AdX_{1}^TB) + vec(dX_{1}AE_{i, j}^TB)$$\n",
    "$$df^2(X) = (B^T \\otimes E_{i, j}A) \\cdot vec(dX^T) + (B^TE_{i, j}A^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = (B^T \\otimes E_{i, j}A) \\cdot K_{m, n} \\cdot vec(dX) + (B^TE_{i, j}A^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = ((B^T \\otimes E_{i, j}A) \\cdot K_{m, n} + B^TE_{i, j}A^T  \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Segunda Derivada (Desde Producto Kronecker):** \n",
    "\n",
    "$$df(X) = ((B^T \\otimes XA) \\cdot K_{m, n} +  ((AX^TB)^T \\otimes I))\\cdot vec(dX)$$\n",
    "$$df^2(X) = ((dB^T \\otimes XA + B^T \\otimes d(XA)) \\cdot K_{m, n} + d(AX^TB)^T \\otimes I + (AX^TB)^T \\otimes dI) \\cdot vec(dX)$$\n",
    "$$df^2(X) = ((B^T \\otimes d(XA)) \\cdot K_{m, n} + d(AX^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = ((B^T \\otimes dXA) \\cdot K_{m, n} + (AdX^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = ((B^T \\otimes E_{i, j}A) \\cdot K_{m, n} + (AE_{i, j}^TB)^T \\otimes I) \\cdot vec(dX)$$\n",
    "$$df^2(X) = ((B^T \\otimes E_{i, j}A) \\cdot K_{m, n} + B^TE_{i, j}A^T \\otimes I) \\cdot vec(dX)$$\n",
    "\n",
    "**Hessiana:**\n",
    "\n",
    "$$H = (B^T \\otimes E_{i, j}A) \\cdot K_{m, n} + B^TE_{i, j}A^T  \\otimes I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[128., 112.,  40.,  25.,  56.,  35., 112., 112.,  45.,  35.,  63.,  49.],\n",
      "        [  0.,   0.,  64.,  72.,   0.,   0.,   0.,   0.,  40.,  56.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,  64.,  72.,   0.,   0.,   0.,   0.,  40.,  56.],\n",
      "        [144., 126.,  56.,  35.,  48.,  30., 126., 126.,  63.,  49.,  54.,  42.],\n",
      "        [  0.,   0.,  72.,  81.,   0.,   0.,   0.,   0.,  45.,  63.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,  72.,  81.,   0.,   0.,   0.,   0.,  45.,  63.],\n",
      "        [ 96.,  84.,   8.,   5.,  32.,  20.,  84.,  84.,   9.,   7.,  36.,  28.],\n",
      "        [  0.,   0.,  48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,  48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.],\n",
      "        [ 40.,  45.,   0.,   0.,   0.,   0.,  25.,  35.,   0.,   0.,   0.,   0.],\n",
      "        [ 64.,  40.,  80.,  70.,  56.,  35.,  72.,  56.,  70.,  70.,  63.,  49.],\n",
      "        [  0.,   0.,   0.,   0.,  40.,  45.,   0.,   0.,   0.,   0.,  25.,  35.],\n",
      "        [ 56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.,   0.,   0.,   0.,   0.],\n",
      "        [ 72.,  45., 112.,  98.,  48.,  30.,  81.,  63.,  98.,  98.,  54.,  42.],\n",
      "        [  0.,   0.,   0.,   0.,  56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.],\n",
      "        [  8.,   9.,   0.,   0.,   0.,   0.,   5.,   7.,   0.,   0.,   0.,   0.],\n",
      "        [ 48.,  30.,  16.,  14.,  32.,  20.,  54.,  42.,  14.,  14.,  36.,  28.],\n",
      "        [  0.,   0.,   0.,   0.,   8.,   9.,   0.,   0.,   0.,   0.,   5.,   7.],\n",
      "        [ 56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.,   0.,   0.],\n",
      "        [ 64.,  40.,  40.,  25., 112.,  98.,  72.,  56.,  45.,  35.,  98.,  98.],\n",
      "        [ 48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.,   0.,   0.],\n",
      "        [ 72.,  45.,  56.,  35.,  96.,  84.,  81.,  63.,  63.,  49.,  84.,  84.],\n",
      "        [ 32.,  36.,   0.,   0.,   0.,   0.,  20.,  28.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  32.,  36.,   0.,   0.,   0.,   0.,  20.,  28.,   0.,   0.],\n",
      "        [ 48.,  30.,   8.,   5.,  64.,  56.,  54.,  42.,   9.,   7.,  56.,  56.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(A, X, B):   \n",
    "    \n",
    "    output = torch.matmul(X, A)\n",
    "    output = torch.matmul(output, X.T)\n",
    "    output = torch.matmul(output, B)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0], [9.0, 5.0]]) \n",
    "A = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "B = torch.tensor([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0], [7.0, 6.0, 4.0]])\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el segundo argumento 1 --> X) (backward-mode)\n",
    "\n",
    "hessian = jacrev(jacrev(Fn, argnums = 1), argnums = 1)(A, X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1] * hessian.shape[2], hessian.shape[3] * hessian.shape[4] * hessian.shape[5])\n",
    "\n",
    "hessian = hessian.T.permute(3, 4, 5, 0, 1, 2).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "[[128. 112.  40.  25.  56.  35. 112. 112.  45.  35.  63.  49.]\n",
      " [  0.   0.  64.  72.   0.   0.   0.   0.  40.  56.   0.   0.]\n",
      " [  0.   0.   0.   0.  64.  72.   0.   0.   0.   0.  40.  56.]\n",
      " [144. 126.  56.  35.  48.  30. 126. 126.  63.  49.  54.  42.]\n",
      " [  0.   0.  72.  81.   0.   0.   0.   0.  45.  63.   0.   0.]\n",
      " [  0.   0.   0.   0.  72.  81.   0.   0.   0.   0.  45.  63.]\n",
      " [ 96.  84.   8.   5.  32.  20.  84.  84.   9.   7.  36.  28.]\n",
      " [  0.   0.  48.  54.   0.   0.   0.   0.  30.  42.   0.   0.]\n",
      " [  0.   0.   0.   0.  48.  54.   0.   0.   0.   0.  30.  42.]\n",
      " [ 40.  45.   0.   0.   0.   0.  25.  35.   0.   0.   0.   0.]\n",
      " [ 64.  40.  80.  70.  56.  35.  72.  56.  70.  70.  63.  49.]\n",
      " [  0.   0.   0.   0.  40.  45.   0.   0.   0.   0.  25.  35.]\n",
      " [ 56.  63.   0.   0.   0.   0.  35.  49.   0.   0.   0.   0.]\n",
      " [ 72.  45. 112.  98.  48.  30.  81.  63.  98.  98.  54.  42.]\n",
      " [  0.   0.   0.   0.  56.  63.   0.   0.   0.   0.  35.  49.]\n",
      " [  8.   9.   0.   0.   0.   0.   5.   7.   0.   0.   0.   0.]\n",
      " [ 48.  30.  16.  14.  32.  20.  54.  42.  14.  14.  36.  28.]\n",
      " [  0.   0.   0.   0.   8.   9.   0.   0.   0.   0.   5.   7.]\n",
      " [ 56.  63.   0.   0.   0.   0.  35.  49.   0.   0.   0.   0.]\n",
      " [  0.   0.  56.  63.   0.   0.   0.   0.  35.  49.   0.   0.]\n",
      " [ 64.  40.  40.  25. 112.  98.  72.  56.  45.  35.  98.  98.]\n",
      " [ 48.  54.   0.   0.   0.   0.  30.  42.   0.   0.   0.   0.]\n",
      " [  0.   0.  48.  54.   0.   0.   0.   0.  30.  42.   0.   0.]\n",
      " [ 72.  45.  56.  35.  96.  84.  81.  63.  63.  49.  84.  84.]\n",
      " [ 32.  36.   0.   0.   0.   0.  20.  28.   0.   0.   0.   0.]\n",
      " [  0.   0.  32.  36.   0.   0.   0.   0.  20.  28.   0.   0.]\n",
      " [ 48.  30.   8.   5.  64.  56.  54.  42.   9.   7.  56.  56.]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos la funcion matricial\n",
    "\n",
    "def Fn(A, X, B):   \n",
    "    \n",
    "    output = jaxnp.matmul(X, A)\n",
    "    output = jaxnp.matmul(output, X.T)\n",
    "    output = jaxnp.matmul(output, B)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Definimos nuestras matrices de ejemplo\n",
    "\n",
    "X = jaxnp.array([[1.0, 2.0], [3.0, 4.0], [9.0, 5.0]]) \n",
    "A = jaxnp.array([[8.0, 9.0], [5.0, 7.0]]) \n",
    "B = jaxnp.array([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0], [7.0, 6.0, 4.0]])\n",
    "\n",
    "# Calculamos la Matriz Hessiana (Indicamos con respecto a que argumento derivamos dos veces en nuestro caso el segundp argumento 1 --> X) (backward-mode)\n",
    "\n",
    "hessian = jax.jacrev(jax.jacrev(Fn, argnums = 1), argnums = 1)(A, X, B)\n",
    "\n",
    "# Redimensionamos\n",
    "\n",
    "new_shape = (hessian.shape[0] * hessian.shape[1] * hessian.shape[2], hessian.shape[3] * hessian.shape[4] * hessian.shape[5])\n",
    "\n",
    "hessian = jaxnp.moveaxis(hessian.T, (0, 1, 2, 3, 4, 5), (3, 4, 5, 0, 1, 2)).reshape(new_shape)\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Hessiana Respecto a X: \n",
      "tensor([[128., 112.,  40.,  25.,  56.,  35., 112., 112.,  45.,  35.,  63.,  49.],\n",
      "        [  0.,   0.,  64.,  72.,   0.,   0.,   0.,   0.,  40.,  56.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,  64.,  72.,   0.,   0.,   0.,   0.,  40.,  56.],\n",
      "        [144., 126.,  56.,  35.,  48.,  30., 126., 126.,  63.,  49.,  54.,  42.],\n",
      "        [  0.,   0.,  72.,  81.,   0.,   0.,   0.,   0.,  45.,  63.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,  72.,  81.,   0.,   0.,   0.,   0.,  45.,  63.],\n",
      "        [ 96.,  84.,   8.,   5.,  32.,  20.,  84.,  84.,   9.,   7.,  36.,  28.],\n",
      "        [  0.,   0.,  48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,  48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.],\n",
      "        [ 40.,  45.,   0.,   0.,   0.,   0.,  25.,  35.,   0.,   0.,   0.,   0.],\n",
      "        [ 64.,  40.,  80.,  70.,  56.,  35.,  72.,  56.,  70.,  70.,  63.,  49.],\n",
      "        [  0.,   0.,   0.,   0.,  40.,  45.,   0.,   0.,   0.,   0.,  25.,  35.],\n",
      "        [ 56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.,   0.,   0.,   0.,   0.],\n",
      "        [ 72.,  45., 112.,  98.,  48.,  30.,  81.,  63.,  98.,  98.,  54.,  42.],\n",
      "        [  0.,   0.,   0.,   0.,  56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.],\n",
      "        [  8.,   9.,   0.,   0.,   0.,   0.,   5.,   7.,   0.,   0.,   0.,   0.],\n",
      "        [ 48.,  30.,  16.,  14.,  32.,  20.,  54.,  42.,  14.,  14.,  36.,  28.],\n",
      "        [  0.,   0.,   0.,   0.,   8.,   9.,   0.,   0.,   0.,   0.,   5.,   7.],\n",
      "        [ 56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  56.,  63.,   0.,   0.,   0.,   0.,  35.,  49.,   0.,   0.],\n",
      "        [ 64.,  40.,  40.,  25., 112.,  98.,  72.,  56.,  45.,  35.,  98.,  98.],\n",
      "        [ 48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  48.,  54.,   0.,   0.,   0.,   0.,  30.,  42.,   0.,   0.],\n",
      "        [ 72.,  45.,  56.,  35.,  96.,  84.,  81.,  63.,  63.,  49.,  84.,  84.],\n",
      "        [ 32.,  36.,   0.,   0.,   0.,   0.,  20.,  28.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  32.,  36.,   0.,   0.,   0.,   0.,  20.,  28.,   0.,   0.],\n",
      "        [ 48.,  30.,   8.,   5.,  64.,  56.,  54.,  42.,   9.,   7.,  56.,  56.]])\n"
     ]
    }
   ],
   "source": [
    "# Definimos Nuestras Matrices\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0], [9.0, 5.0]]) \n",
    "A = torch.tensor([[8.0, 9.0], [5.0, 7.0]]) \n",
    "B = torch.tensor([[8.0, 9.0, 6.0], [5.0, 7.0, 1.0], [7.0, 6.0, 4.0]])\n",
    "\n",
    "I = torch.eye(3) \n",
    "\n",
    "# Añadimos Dimensiones Adicionales\n",
    "\n",
    "A = torch.unsqueeze(A, dim = 0)\n",
    "B = torch.unsqueeze(B, dim = 0)\n",
    "I = torch.unsqueeze(I, dim = 0)\n",
    "\n",
    "# Tensor Canonico\n",
    "\n",
    "E1 = torch.tensor([[1, 0], [0, 0], [0, 0]], dtype = torch.float32)\n",
    "E2 = torch.tensor([[0, 0], [1, 0], [0, 0]], dtype = torch.float32)\n",
    "E3 = torch.tensor([[0, 0], [0, 0], [1, 0]], dtype = torch.float32)\n",
    "E4 = torch.tensor([[0, 1], [0, 0], [0, 0]], dtype = torch.float32)\n",
    "E5 = torch.tensor([[0, 0], [0, 1], [0, 0]], dtype = torch.float32)\n",
    "E6 = torch.tensor([[0, 0], [0, 0], [0, 1]], dtype = torch.float32)\n",
    "\n",
    "E_ij = torch.stack([E1, E2, E3, E4, E5, E6])\n",
    "\n",
    "# Producto Kronecker\n",
    "\n",
    "term_1 = torch.kron(B.permute(0, 2, 1).contiguous(), E_ij @ A)\n",
    "term_2 = torch.kron(B.permute(0, 2, 1).contiguous() @ E_ij @ A.permute(0, 2, 1).contiguous(), I)\n",
    "\n",
    "# Conmutamos ya que existe vec(dX.T)\n",
    "\n",
    "n = A.shape[2]\n",
    "m = X.shape[0] \n",
    "\n",
    "commuted_indices = torch.arange(n * m).reshape(m, n).T.reshape(-1)\n",
    "\n",
    "term1_commuted = term_1[:, :, commuted_indices]\n",
    "\n",
    "# Hessiana\n",
    "\n",
    "hessian = term1_commuted.reshape(term_1.shape) + term_2\n",
    "hessian = hessian.permute(0, 2, 1).reshape(12, 27).T\n",
    "\n",
    "# Visualizamos\n",
    "\n",
    "print(f'La Hessiana Respecto a X: \\n{hessian}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatrixCalculus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
